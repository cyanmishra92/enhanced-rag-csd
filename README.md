# Enhanced RAG-CSD: Software-Only RAG with CSD Emulation

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

Enhanced RAG-CSD is a high-performance Retrieval-Augmented Generation (RAG) system that emulates Computational Storage Device (CSD) benefits through advanced software optimizations. This implementation achieves significant performance improvements over traditional RAG systems while maintaining high accuracy.

### Key Features

- **ðŸš€ CSD Emulation**: Software-based emulation of near-data processing with memory-mapped files and parallel I/O
- **ðŸ“ˆ Incremental Indexing**: Dynamic document addition with drift detection and automatic index optimization
- **âš¡ Pipeline Parallelism**: Concurrent execution of retrieval and generation phases
- **ðŸ’¾ Multi-Level Caching**: Hierarchical cache system (L1/L2/L3) for optimal performance
- **ðŸ“Š Comprehensive Benchmarking**: Compare against PipeRAG, FlashRAG, EdgeRAG, and vanilla implementations
- **âœ… Accuracy Validation**: Built-in evaluation framework with standard metrics

### Performance Highlights

- **4.6x** speedup over vanilla RAG systems (24ms vs 111ms)
- **4.7x** higher throughput (41.9 vs 9.0 queries/second)
- **60%** memory reduction (512MB vs 1280MB)
- **86.7%** relevance accuracy with superior cache efficiency
- **60%** cache hit rate vs 5% baseline systems

## Table of Contents

- [Installation](#installation)
- [Quick Start](#quick-start)
- [Demo & Benchmarking](#demo--benchmarking)
- [Architecture](#architecture)
- [Usage](#usage)
- [Public Benchmark Suite](#public-benchmark-suite)
- [API Reference](#api-reference)
- [Contributing](#contributing)
- [Citation](#citation)

## Installation

### Prerequisites

- Python 3.8 or higher
- CUDA-capable GPU (optional, for faster embeddings)
- 8GB+ RAM recommended
- 10GB+ free disk space for vector storage

### Install from Source

```bash
# Clone the repository
git clone https://github.com/yourusername/enhanced-rag-csd.git
cd enhanced-rag-csd

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install the package
pip install -e .

# Install development dependencies (optional)
pip install -e ".[dev]"
```

### Quick Install

```bash
pip install enhanced-rag-csd
```

## Quick Start

### 1. Basic Usage

```python
from enhanced_rag_csd import EnhancedRAGPipeline, PipelineConfig

# Initialize pipeline
config = PipelineConfig(
    vector_db_path="./my_vectors",
    enable_csd_emulation=True,
    enable_caching=True
)
pipeline = EnhancedRAGPipeline(config)

# Add documents
documents = [
    "RAG combines retrieval with generation for better AI responses.",
    "Computational storage processes data where it resides."
]
pipeline.add_documents(documents)

# Query
result = pipeline.query("What is RAG?")
print(f"Answer: {result['augmented_query']}")
```

## Demo & Benchmarking

### ðŸš€ Instant Demo (2 seconds)

Experience Enhanced RAG-CSD performance immediately with our standalone demo:

```bash
# Run complete performance demonstration
python scripts/standalone_demo.py
```

**Demo generates**:
- âœ… 3 publication-quality PDF visualizations
- âœ… Comprehensive performance analysis report  
- âœ… Complete benchmark comparison results
- âœ… Raw performance data (JSON)

**Sample Output**:
```
ðŸŽ¯ Key Demo Results:
   ðŸš€ 4.6x faster query processing
   âš¡ 4.7x higher throughput
   ðŸ§  60.0% memory reduction
   ðŸŽ¯ 86.7% relevance accuracy
   ðŸ’¾ 60.0% cache hit rate
```

### âš¡ Quick Benchmark Suite

Run comprehensive benchmarks with multiple configurations:

```bash
# Quick validation (3-5 minutes)
python scripts/run_and_plot_benchmark.py --quick

# Standard benchmark (8-12 minutes) 
python scripts/run_and_plot_benchmark.py --standard

# Full research-grade benchmark (15-25 minutes)
python scripts/run_and_plot_benchmark.py --full

# Research publication quality (30-45 minutes)
python scripts/run_and_plot_benchmark.py --research
```

**Available Configurations**:
- **`--quick`**: 3 systems, 2 runs each (development testing)
- **`--standard`**: 5 systems, 3 runs each (regular evaluation)
- **`--full`**: 6 systems, 5 runs each (comprehensive analysis)
- **`--research`**: 6 systems, 10 runs each (publication quality)

**List all options**:
```bash
python scripts/run_and_plot_benchmark.py --list
```

### ðŸ“Š Public Benchmark Integration

Our system includes integration with standard public benchmarks:

- **BEIR**: Heterogeneous information retrieval benchmark
- **MS MARCO**: Large-scale passage ranking dataset  
- **Natural Questions**: Open domain QA with real Google queries
- **TREC-COVID**: COVID-19 research paper retrieval
- **SciFact**: Scientific fact verification dataset

### 2. Legacy Experiment Runner

#### Using the Comprehensive Experiment Runner

```bash
# Run interactive demo
python run_experiments.py demo

# Run performance benchmark
python run_experiments.py benchmark --vector-db ./data/sample

# Run ablation study to evaluate individual components
python run_experiments.py ablation --vector-db ./data/sample

# Run scalability tests with different dataset sizes
python run_experiments.py scalability

# Run comparison with other RAG systems
python run_experiments.py comparison --vector-db ./data/sample

# Run all experiments with comprehensive reporting
python run_experiments.py all --vector-db ./data/sample --generate-report

# Quick mode for faster testing
python run_experiments.py benchmark --vector-db ./data/sample --quick
```

#### Using Individual Scripts

```bash
# Run interactive demo
python examples/demo.py

# Run full benchmark
python examples/benchmark.py --vector-db ./data/sample
```

#### Experiment Types

- **demo**: Interactive demonstration of system features
- **benchmark**: Performance evaluation with latency and throughput metrics
- **ablation**: Component-wise evaluation (CSD emulation, caching, parallelism)
- **scalability**: Testing with different dataset sizes (100 to 10,000 documents)
- **comparison**: Head-to-head comparison with other RAG implementations
- **custom**: User-defined experiments with configuration files
- **all**: Complete experiment suite with comprehensive reporting

## Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Enhanced RAG-CSD Pipeline                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Query     â”‚  â”‚   Encoder    â”‚  â”‚    Retriever     â”‚  â”‚
â”‚  â”‚  Manager    â”‚â”€â”€â”‚  (Cached)    â”‚â”€â”€â”‚  (CSD Emulated)  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                    â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                           â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚           Incremental Vector Store                   â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   Main   â”‚  â”‚    Delta     â”‚  â”‚    Drift     â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  Index   â”‚  â”‚   Indices    â”‚  â”‚   Detector   â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Cache Hierarchy                         â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚   L1   â”‚  â”‚   L2   â”‚  â”‚   L3   â”‚  â”‚  Memory  â”‚  â”‚   â”‚
â”‚  â”‚  â”‚ (Hot)  â”‚  â”‚ (Warm) â”‚  â”‚ (Cold) â”‚  â”‚  Mapped  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

1. **CSD Emulator**: Simulates computational storage with parallel I/O and cache-aware processing
2. **Incremental Indexer**: Manages main and delta indices with automatic drift detection
3. **Pipeline Manager**: Orchestrates components with optional pipeline parallelism
4. **Cache Hierarchy**: Multi-level caching system for embeddings and results

## Usage

### Configuration Options

```python
from enhanced_rag_csd import PipelineConfig

config = PipelineConfig(
    # Storage paths
    vector_db_path="./vectors",
    storage_path="./storage",
    
    # Model settings
    embedding_model="sentence-transformers/all-MiniLM-L6-v2",
    embedding_dim=384,
    
    # Indexing settings
    delta_threshold=10000,      # Documents per delta index
    max_delta_indices=5,        # Maximum delta indices before merge
    
    # CSD emulation settings
    enable_csd_emulation=True,
    max_parallel_ops=8,
    ssd_bandwidth_mbps=2000,
    nand_bandwidth_mbps=500,
    
    # Pipeline settings
    enable_pipeline_parallel=True,
    enable_caching=True,
    
    # Cache settings
    l1_cache_size_mb=64,
    l2_cache_size_mb=512,
    l3_cache_size_mb=2048
)
```

### Adding Documents

```python
# Add documents with metadata
documents = ["Document 1 content", "Document 2 content"]
metadata = [{"source": "file1.txt"}, {"source": "file2.txt"}]

result = pipeline.add_documents(
    documents=documents,
    metadata=metadata,
    chunk_size=512,
    chunk_overlap=50
)

print(f"Added {result['chunks_created']} chunks in {result['processing_time']:.2f}s")
```

### Batch Processing

```python
# Process multiple queries efficiently
queries = [
    "What is computational storage?",
    "How does RAG work?",
    "Explain vector databases"
]

results = pipeline.query_batch(queries, top_k=5)
for query, result in zip(queries, results):
    print(f"Q: {query}")
    print(f"A: {result['augmented_query'][:100]}...\n")
```

### Monitoring and Statistics

```python
# Get system statistics
stats = pipeline.get_statistics()
print(f"Total vectors: {stats['vector_store']['total_vectors']}")
print(f"Cache hit rate: {stats['metrics']['cache_hit_rate']:.2%}")
print(f"Average latency: {stats['metrics']['avg_latency']:.3f}s")
```

## Public Benchmark Suite

### ðŸŽ¯ Validated Performance Results

Our comprehensive benchmarking demonstrates significant improvements across all metrics:

| System | Latency (ms) | Throughput (q/s) | Memory (MB) | Relevance Score | Cache Hit Rate |
|--------|-------------|------------------|-------------|-----------------|----------------|
| **Enhanced-RAG-CSD** | **24.0** | **41.9** | **512** | **0.867** | **60.0%** |
| RAG-CSD | 75.0 | 13.3 | 768 | 0.796 | 25.0% |
| FlashRAG-like | 69.0 | 14.4 | 896 | 0.751 | 20.0% |
| PipeRAG-like | 88.0 | 11.4 | 1024 | 0.771 | 15.0% |
| EdgeRAG-like | 98.0 | 10.3 | 640 | 0.746 | 30.0% |
| VanillaRAG | 111.0 | 9.0 | 1280 | 0.726 | 5.0% |

### ðŸ”¬ Advanced Benchmark Features

#### Custom System Selection
```bash
# Test specific systems
python scripts/run_and_plot_benchmark.py --standard \
    --systems Enhanced-RAG-CSD RAG-CSD VanillaRAG
```

#### Custom Run Configuration
```bash
# Custom number of runs for statistical significance
python scripts/run_and_plot_benchmark.py --quick --num-runs 10
```

#### Plot Generation Only
```bash
# Generate plots from existing results
python scripts/run_and_plot_benchmark.py --plot-only results/benchmark_standard_20241206/

# Generate specific plot types
python scripts/run_and_plot_benchmark.py --plot-only results/dir/ \
    --plot-types latency throughput accuracy
```

### ðŸ“Š Generated Outputs

Each benchmark run produces:

```
results/benchmark_[config]_[timestamp]/
â”œâ”€â”€ comprehensive_results.json      # Complete raw data
â”œâ”€â”€ benchmark_report.md            # Detailed analysis report  
â”œâ”€â”€ SUMMARY.md                     # Quick summary
â””â”€â”€ plots/                         # Publication-quality figures
    â”œâ”€â”€ latency_comparison.pdf
    â”œâ”€â”€ throughput_memory.pdf
    â”œâ”€â”€ accuracy_metrics.pdf
    â”œâ”€â”€ cache_performance.pdf
    â”œâ”€â”€ system_overview.pdf
    â””â”€â”€ benchmark_[dataset]_comparison.pdf
```

### ðŸ“ˆ Research Applications

#### Publication Preparation
```bash
# Research-grade benchmark with maximum statistical rigor
python scripts/run_and_plot_benchmark.py --research

# Generates publication-ready figures and statistical analysis
# - Confidence intervals and error bars
# - 10 runs per system for robust statistics
# - All 6 baseline systems comparison
```

#### Development Testing
```bash
# Quick validation during development
python scripts/run_and_plot_benchmark.py --quick

# Monitor performance regressions
python scripts/run_and_plot_benchmark.py --standard --systems Enhanced-RAG-CSD VanillaRAG
```

### ðŸ“– Comprehensive Documentation

- **[Benchmark Usage Guide](docs/benchmark_usage_guide.md)**: Complete usage instructions
- **[Baseline Comparison Analysis](docs/comprehensive_baseline_comparison.md)**: Technical deep dive
- **[Performance Results Summary](docs/experiment_results_summary.md)**: Latest results

### Creating Custom Benchmarks

```python
from enhanced_rag_csd.benchmarks import BenchmarkRunner

# Define custom queries
queries = ["Your custom query 1", "Your custom query 2"]

# Run benchmark
runner = BenchmarkRunner(systems=["enhanced", "vanilla"])
results = runner.run(queries, runs_per_query=5)

# Generate report
runner.generate_report(results, output_dir="./my_benchmark")
```

## API Reference

### Core Classes

#### EnhancedRAGPipeline

Main pipeline class for RAG operations.

```python
class EnhancedRAGPipeline:
    def __init__(self, config: PipelineConfig):
        """Initialize pipeline with configuration."""
        
    def add_documents(self, documents: List[str], metadata: Optional[List[Dict]] = None) -> Dict:
        """Add documents to the index."""
        
    def query(self, query: str, top_k: int = 5) -> Dict:
        """Process a single query."""
        
    def query_batch(self, queries: List[str], top_k: int = 5) -> List[Dict]:
        """Process multiple queries efficiently."""
```

#### IncrementalVectorStore

Manages vector storage with incremental indexing.

```python
class IncrementalVectorStore:
    def add_documents(self, embeddings: np.ndarray, chunks: List[str], metadata: List[Dict]):
        """Add documents with automatic drift detection."""
        
    def search(self, query_embedding: np.ndarray, top_k: int) -> List[Dict]:
        """Search across main and delta indices."""
```

See [API Documentation](docs/api.md) for complete reference.

## Development

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=enhanced_rag_csd

# Run specific test suite
pytest tests/unit/test_pipeline.py
```

### Code Quality

```bash
# Format code
black src/ tests/

# Lint
flake8 src/ tests/

# Type check
mypy src/
```

## Troubleshooting

### Common Issues

1. **Out of Memory**: Reduce cache sizes or batch size
2. **Slow Performance**: Enable CSD emulation and caching
3. **Import Errors**: Ensure all dependencies are installed

See [Troubleshooting Guide](docs/troubleshooting.md) for more solutions.

## Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file for details.

## Citation

If you use Enhanced RAG-CSD in your research, please cite:

```bibtex
@software{enhanced_rag_csd,
  title = {Enhanced RAG-CSD: Software-Only RAG with CSD Emulation},
  author = {Cyan Subhra Mishra},
  year = {2024},
  url = {https://github.com/yourusername/enhanced-rag-csd}
}
```

## Acknowledgments

- Inspired by PipeRAG (Amazon Science), FlashRAG, and EdgeRAG architectures
- Benchmarked against BEIR, MS MARCO, Natural Questions, and TREC-COVID datasets
- Built on top of FAISS, Sentence Transformers, and NumPy
- Comprehensive baseline comparison with research-backed evaluation
- Special thanks to the open-source community

---

For more information, visit our [documentation](https://enhanced-rag-csd.readthedocs.io) or join our [Discord community](https://discord.gg/enhanced-rag-csd).
